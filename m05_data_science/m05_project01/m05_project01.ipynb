{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/4/47/Logo_UTFSM.png\" width=\"200\" alt=\"utfsm-logo\" align=\"left\"/>\n",
    "\n",
    "# MAT281\n",
    "### Aplicaciones de la Matemática en la Ingeniería"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Proyecto 01: Clasificación de dígitos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Instrucciones\n",
    "\n",
    "* Completa tus datos personales (nombre y rol USM) en siguiente celda.\n",
    "* Debes _pushear_ tus cambios a tu repositorio personal del curso.\n",
    "* Como respaldo, debes enviar un archivo .zip con el siguiente formato `mXX_projectYY_apellido_nombre.zip` a alonso.ogueda@gmail.com, debe contener todo lo necesario para que se ejecute correctamente cada celda, ya sea datos, imágenes, scripts, etc.\n",
    "* Se evaluará:\n",
    "    - Soluciones\n",
    "    - Código\n",
    "    - Que Binder esté bien configurado.\n",
    "    - Al presionar  `Kernel -> Restart Kernel and Run All Cells` deben ejecutarse todas las celdas sin error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "__Nombre__: Claudia Alvarez Latuz\n",
    "\n",
    "__Rol__: 201610006-7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Clasificación de dígitos\n",
    "En este laboratorio realizaremos el trabajo de reconocer un dígito a partir de una imagen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Contenidos\n",
    "* [K Nearest Neighbours](#k_nearest_neighbours)\n",
    "* [Exploración de Datos](#data_exploration)\n",
    "* [Entrenamiento y Predicción](#train_and_prediction)\n",
    "* [Selección de Modelo](#model_selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='k_neirest_neighbours'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## K Nearest Neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "El algoritmo **k Nearest Neighbors** es un método no paramétrico: una vez que el parámetro $k$ se ha fijado, no se busca obtener ningún parámetro adicional.\n",
    "\n",
    "Sean los puntos $x^{(i)} = (x^{(i)}_1, ..., x^{(i)}_n)$  de etiqueta $y^{(i)}$ conocida, para $i=1, ..., m$.\n",
    "\n",
    "El problema de clasificación consiste en encontrar la etiqueta de un nuevo punto $x=(x_1, ..., x_m)$ para el cual no conocemos la etiqueta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "La etiqueta de un punto se obtiene de la siguiente forma:\n",
    "* Para $k=1$, **1NN** asigna a $x$ la etiqueta de su vecino más cercano. \n",
    "* Para $k$ genérico, **kNN** asigna a $x$ la etiqueta más popular de los k vecinos más cercanos. \n",
    "\n",
    "El modelo subyacente a kNN es el conjunto de entrenamiento completo. A diferencia de otros métodos que efectivamente generalizan y resumen la información (como regresión logística, por ejemplo), cuando se necesita realizar una predicción, el algoritmo kNN mira **todos** los datos y selecciona los k datos más cercanos, para regresar la etiqueta más popular/más común. Los datos no se resumen en parámetros, sino que siempre deben mantenerse en memoria. Es un método por tanto que no escala bien con un gran número de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "En caso de empate, existen diversas maneras de desempatar:\n",
    "* Elegir la etiqueta del vecino más cercano (problema: no garantiza solución).\n",
    "* Elegir la etiqueta de menor valor (problema: arbitrario).\n",
    "* Elegir la etiqueta que se obtendría con $k+1$ o $k-1$ (problema: no garantiza solución, aumenta tiempo de cálculo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "La cercanía o similaridad entre los datos se mide de diversas maneras, pero en general depende del tipo de datos y del contexto.\n",
    "\n",
    "* Para datos reales, puede utilizarse cualquier distancia, siendo la **distancia euclidiana** la más utilizada. También es posible ponderar unas componentes más que otras. Resulta conveniente normalizar para poder utilizar la noción de distancia más naturalmente.\n",
    "\n",
    "* Para **datos categóricos o binarios**, suele utilizarse la distancia de Hamming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "A continuación, una implementación de \"bare bones\" en numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def knn_search(X, k, x):\n",
    "    \"\"\" find K nearest neighbours of data among D \"\"\"\n",
    "    # Distancia euclidiana\n",
    "    d = np.linalg.norm(X - x, axis=1)\n",
    "    # Ordenar por cercania\n",
    "    idx = np.argsort(d)\n",
    "    # Regresar los k mas cercanos\n",
    "    id_closest = idx[:k] \n",
    "    return id_closest, d[id_closest].max()\n",
    "\n",
    "def knn(X,Y,k,x):\n",
    "    # Obtener los k mas cercanos\n",
    "    k_closest, dmax = knn_search(X, k, x)\n",
    "    # Obtener las etiquetas\n",
    "    Y_closest = Y[k_closest]\n",
    "    # Obtener la mas popular\n",
    "    counts = np.bincount(Y_closest.flatten())\n",
    "    # Regresar la mas popular (cualquiera, si hay empate)\n",
    "    return np.argmax(counts), k_closest, dmax\n",
    "\n",
    "def plot_knn(X, Y, k, x):\n",
    "    y_pred, neig_idx, dmax = knn(X, Y, k, x)    \n",
    "    # plotting the data and the input point\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    plt.plot(x[0, 0], x[0, 1], 'ok', ms=16)\n",
    "    m_ob = Y[:, 0] == 0\n",
    "    plt.plot(X[m_ob, 0], X[m_ob, 1], 'ob', ms=8)\n",
    "    m_sr = Y[:,0] == 1\n",
    "    plt.plot(X[m_sr, 0], X[m_sr, 1], 'sr', ms=8)\n",
    "\n",
    "    # highlighting the neighbours\n",
    "    plt.plot(X[neig_idx, 0], X[neig_idx, 1], 'o', markerfacecolor='None', markersize=24, markeredgewidth=1)\n",
    "\n",
    "    # Plot a circle\n",
    "    x_circle = dmax * np.cos(np.linspace(0, 2*np.pi, 360)) +  x[0, 0]\n",
    "    y_circle = dmax * np.sin(np.linspace(0, 2*np.pi, 360)) +  x[0, 1]\n",
    "    plt.plot(x_circle, y_circle, 'k', alpha=0.25)\n",
    "    plt.show();\n",
    "\n",
    "    # Print result\n",
    "    if y_pred==0:\n",
    "        print(\"Prediccion realizada para etiqueta del punto = {} (circulo azul)\".format(y_pred))\n",
    "    else:\n",
    "        print(\"Prediccion realizada para etiqueta del punto = {} (cuadrado rojo)\".format(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Puedes ejecutar varias veces el código anterior, variando el número de vecinos `k` para ver cómo afecta el algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAHSCAYAAADfUaMwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de3Cc133m+ed0AyBANECAxKUJgPcLZN50gyXGpSSe8dqWbU157c26JCdWxRcpEsdTM1GZtDMzHobjcc2Y0micVEwpsq3xONnQ64wcx7eJ7c2WY2sTWQJtihQhkQQICgApoAGSANEgro2zfzRAgiAaaHS/3e+lv5+qLhL9NoHDF8D79DnvOb9jrLUCAADuCbndAAAACh1hDACAywhjAABcRhgDAOAywhgAAJcRxgAAuKzIrS9cU1NjN27c6NaXBwAg744dOzZgra2d/7xrYbxx40a1tra69eUBAMg7Y8ybCz3PMDUAAC4jjAEAcBlhDACAywhjAABcRhgDAOAywhgAAJcRxgAAuIwwBgDAZYQxAAAuI4wBAHAZYQwAgMsIYwAAXLZkGBtjnjfGxIwxr6U4bowxf2qMaTfGnDDG3OV8MwEACK50esbfkHT/IsffJ2nbzONRSc9k3ywAAArHkmFsrf25pMuLvOSDkr5pk16SVGWMWetUA9MRj0sHD0q1tVIolPzz4MHk88g9zj/gomhUMib1Ixp1u4VIgxP7GTdK6p7zcc/Mc2858LmXFI9Le/dKHR3S2FjyuYEB6fBh6YUXpJdekiKRfLSkMHH+AZf19WV3HJ7gxAQus8BzdsEXGvOoMabVGNPa39/vwJeWnnzy5iCYNTaWfP7JJx35MkiB8w8A2XMijHskrZvzcZOkiwu90Fr7nLW2xVrbUltb68CXlo4cuTUIZo2NSc9wBzunOP8AkD0nwvh7kh6emVW9V9KQtTYvQ9SSdOlSdseRHc4/sATu6SINS94zNsYclfROSTXGmB5JByUVS5K19llJP5L0fkntkq5J+niuGruQNWuS9ygXO47c4fwDS+CeLtKwZBhbax9a4riV9C8da9Ey7duXnCy00FBpaan0+OP5b1Mh4fwDQPZ8X4Fr/35py5bkhX+u0tLk8/v3u9OuQsH59zaWnQH+4PswjkSSy2cOHLj5gnPggEeX1QTs/pHvzr9bXPi+zy47O3w4eSvB2hvLzvbuJZADo74+u+PwBJMcZc6/lpYW29ra6srXdpVZaCXYPC59T5BDLnzfDx5c/BbCgQPSoUOOfkkshN95zGGMOWatbZn/vO97xgAWFuhlZwEbYQIIY8BJqULCBYFedsYMZQRM8MKYd8xwk4dCYKllZSw7yxMH7+kyIS+4ghfGvGMGJCWXnc2f5T7L18vO/PaGurc3eU841aO3N61Pw4S8YAteGAOQFOBlZwX6hpo68MFGGAMBxbKz3HBrqDjQE/IQwKVNXl9GEI0u/s6+vj7tYSt4UKaTtfi+py/dc5yD3/OFtgyVbow25PJNTii0+H8pFJISidx8bTiHpU1e4dD9I/gY33ffcnOomAl5wUYYAwieHFWdcnOoOLAT8iCJMAacRWlCb8jRSIOba7cDOyEPkoIYxlwM4SZuQwSam0PFTMgLtuCFMRdDINgcesOdyaxot4eKI5FkPfFYLDlZKxZLfkwQ+1/wZlMDwBIynRXt5mxqBAOzqZEWyu2hEGQ6K5qhYuQKPWNcx7t+FIra2mQpycWOx2L5aw8KBz1jLIlyeygUgd7RCr5EGOM6yu15G7cQnEMBDXgNYYzr6C14Fzv2OMvtWdHAfIQxrqO34F3cQnAWBTTgNYRx0EWjycL6qR5z9oalt+Bd3EJwFrOi4TXMpnZDPnduWsYuVsym9i527AGCgdnUXrLU5ugubZ5Ob8G7uIWAfGPCYH7RM3ZDPvdc9vr+zkjLwYPJyVoLDVWXlibfMB06lP92IZgYJcsdesaAjzHhCPnEhMH8I4yBbC1jklymuIWAfGLCYP4RxkC20pgD4MT9t2Xt2JOHNwgILmoO5B9hDORB3gt2eHSSIPyBCYP5RxgHnUN7vyI73H/zHmYLp0bNgfxjNrUb8rnOGLmXxox1o9S/ZznZIYhZ9ItitvDiOD+5w2xqL+ntTV4IUz0I4oLC/bf8Y7bw4pgwmH/0jFHQ4vHkhffIkWQorlmTHKLbv38ZFxx6xr7DfsZwS6qecZEbjQG8YKGhuNmJVS+84GwPoLQ0dcEO7r/lH7OF4TUMU6NgOTZUucQkuOm6egp2eAyzheE1hDEKlmOFDZaYAxDq683//Tdm0S+K2cLwGsI4CyyN8Ld8DlUuq2CHEzw+SdDt3x3Ki8JrmMCVIab++x+TeNzhld+d2cl7zzxzY/Le448vc/IesEwsbXIYSyP8j6FKd3jldyfvoxXAIugZZ4helf95pYdWaPjdQSGjZ+wwlkb4H4UN3MHvDnAresYZ4t09kBl+d1DI6Bk7jPuNQGb43QFuRRhniKURQGb43QFuRRhniPuNQGb43QFuxT1jAADyhHvGAAB4FGEMAIDLCGMAQM64XYfcL9jPGACQE/ncM9zv6BkDAHLCK3XI/YAwBgDkhGN7hhcAwhgA0hWNSsakfkSjbrfQU6hDnj7CGADS1deX3fECs2ZNdscLCWEMAMgJ6pCnjzAGAOQEdcjTRxgDAHKCOuTpI4yBgKC4ArwoEpEOHUruUZ1IJP88dIggno8wdhkXUDhhtrjC4cPJogrW3iiusHcvP0+A1xHGLuICCqdQXAFeRGcjfYSxi7iAwikUV8iT+vrsjhcQOhvLQxi7iAsonEJxhTzp7U2mSqpHb6/bLfQMOhvLQxi7iAsonEJxBXgNnY3lIYxdxAUUTqG4AryGzsbyEMYu4gIKp1BcAV5DZ2N5CGMXcQGFUyiuAK+hs7E8xlq79IuMuV/Sn0gKS/qatfa/zDu+StJfSlovqUjSU9ba/77Y52xpabGtra2Ztjsw4vHkRIZnnkkO26xZk/wh3b+fCygA/5qdTT1/EtdsZ6NQ3yQaY45Za1vmP79kz9gYE5b0FUnvk7RD0kPGmB3zXvYvJbVZa2+X9E5J/9UYU5J1qwsA1WkABFG6ozWsRU4qSuM190hqt9aekyRjzLckfVBS25zXWEkVxhgjKSLpsqQph9sKAPCR2c7GoUMLH1+o9zy7FvmFFwqr95zOPeNGSd1zPu6ZeW6uP5P0NkkXJZ2U9K+ttdOOtBAAkHNu9FBZi3xDOmFsFnhu/o3m90o6LqlB0h2S/swYU3nLJzLmUWNMqzGmtb+/f9mNRfYYEgIwX6bVsrK9nrAW+YZ0wrhH0ro5Hzcp2QOe6+OSvmOT2iV1Srpt/iey1j5nrW2x1rbU1tZm2mZkiPJ0ABaSSQ/ViesJa5FvSCeMX5G0zRizaWZS1oOSvjfvNV2S3iVJxph6Sc2SzjnZUGSPISEAC8mkh+rE9YS1yDcsGcbW2ilJn5b0Y0mvS/q2tfaUMeYxY8xjMy/7gqR3GGNOSvp7SZ+11g7kqtHIDENCABaSSQ/ViesJa5FvSKvoh7X2R9ba7dbaLdbaL84896y19tmZv1+01r7HWrvbWrvLWvuXuWw0MsOQUPAwB8D/vPA9zKSH6sT1hMJHN1CBq4AwJBQszAHwP698DzPpoTpxPaFy3A2EcQFhSChYmAPgf175HmbSQ3XqekLho6S0ymHmAuUw84/ydMFSW5vsRS12PBbLX3uwfF76Hi63NC/Xk8xkXA4TwcGQULAwB8D/vPQ9XG4PleuJs+gZAz7lpV4VMsP3sPDQMwYChjkA/sf3ELMIY8CnWBbif3wPMYswBnyKe3b+x/cQs7hnDAD5FI1KfX2pj9fXS729+WsP8op7xgDgBYsFcTrHEUiEMQAALiOM4RleqNELAG4ocrsBgLRwNZ/ZGr0vvMBkFgDBRs8YnuCVGr0A4AbCGJ7AXssAChlhDE/wUo1eAMg3whiewF7LKBj19dkdRyARxvAEavSiYPT2StamflDwoyARxoUoGpWMSf2IRvPeJGr0ItA8+DsHbyGMC5EHKwBRoxeB5sHfOXgLtakLkTFLv8alnwsgkPidwwxqUwMA4FGEMQAALiOMAQBwGWEMAIDLCGMAAFxGGBciKgAB+cXvHJZAGAfAsvcBpgIQkF/8zmEJ7Gfsc+wDDAD+R884H3JYCo99gAHA/wjjfMhhKTwv7gO87GFzAChwDFP7nNf2AWbYHACWj56xz3ltH2CGzQFg+Qhjn/PaPsBeHDYHAK8jjH3Oa/sAe23YHAD8gDD2Oa/tA+y1YXMA8APCOAAiEenQISkWkxKJ5J+HDrkzUcprw+YA4AeEcT7koxReDtcyL4fXhs0RQB75WQecRBjnQz5K4eVwLfNyeG3YHAHkkZ915FEBvAEz1lpXvnBLS4ttbW115WsHkjFLv8al7zXgKH7WC0+AvufGmGPW2pb5z9MzBgDAZYQxAAAuI4wBAHAZYQwAgMsIYwAAXEYYB0U+1jIDXsDPOgKIMA6KfKxlhuPY+zkD/KwXngJ4A8Z+xoBL2Pu5AESjixchqa/nzUM6CuAc0TMGXMLezwWAamFIE2EMuIS9nwHMIowBl7D3M4BZhDHgEvZ+BjCLMAZcwt7PAGYRxoBL2PsZwCzCGHAJez8DmMV+xgCQK6wzxjyp9jOm6AcA5ApBizQxTJ0FShkCAJxAzzhDlDIEADiFnnGGKGUIAHAKYZwhShkCAJxCGGeIUoYAAKcQxhmilCEAwCmEcYYoZQgAcAphnCFKGQLpYQkgsDTCOEOUMgSWNrsE8PDh5NI/a28sAdy7l0AGZhHGWYhEpEOHpFhMSiSSfx46RBADs1gCCKSHMAaQMywBBNKTVhgbY+43xpw2xrQbYz6X4jXvNMYcN8acMsb8g7PNBOBHLAEE0rNkOUxjTFjSVyS9W1KPpFeMMd+z1rbNeU2VpCOS7rfWdhlj6nLVYAD+sWZN8h7xYscBpNczvkdSu7X2nLV2QtK3JH1w3ms+Kuk71touSbLWxpxtJgA/YgkgkJ50wrhRUvecj3tmnptru6RqY8zPjDHHjDEPL/SJjDGPGmNajTGt/f39mbUYgG+wBDBN0ahkTOpHNJq3prAUzR3phLFZ4Dk77+MiSXdL+oCk90r6vDFm+y3/yNrnrLUt1tqW2traZTcWgL+wBDBNfX3ZHXcIS9Hck04Y90haN+fjJkkXF3jN31lrR6y1A5J+Lul2Z5oI+Be9DJYA+glL0dxjrJ3fyZ33AmOKJJ2R9C5JFyS9Iumj1tpTc17zNkl/pmSvuETSy5IetNa+lurztrS02NbW1qz/A4BXLbTntXRjiJaeIa4zCw1AzrPEtdoJtbWLT7irrU2+mULmjDHHrLUt859fsmdsrZ2S9GlJP5b0uqRvW2tPGWMeM8Y8NvOa1yX9naQTSgbx1xYLYqAQ0MuA37AUzT1L9oxzxYmecTyevKAdOZL8IVmzJjl7c/9+ehxwH70MpI2eccHIuGfsVUw0gNfRy4DfsBTNPb4NY4YA4XXseQ2/YSmae3wbxtS8hddl0stg9nWBqq/P7rhDWIrmHt/eMw6FFr+FEgoll1EAblnubGpmXwPBF7h7xgwBwuuW28vg1gtQuHwbxkw0gB8sp+AFt16AwuXbMGaiAYKG2ddA4fJtGDPRAEHDrRegcPk2jCVq3iJYuPUCFC5fhzEQJNx6AQoXYQx4BLdegMJFGAMe4rdbLxQpAZxBGAPISNDqw/PGAm4ijAFkJEhFSoL2xgL+QxgDyEiQipQE6Y0F/IkwDqJoNLk/aqpHNOp2CxEAQSpSEqQ3FvAnwjiI+vqyOw6kIUhFSoL0xgL+RBgDyEiQipQE6Y0F/IkwBpCRIBUpCdIbC/gTYQwgI0EqUhKkNxbwJ8IYQMb8VqQklSC9sUB23Fpvbqy1uf0KKbS0tNjW1lZXvnbgGbP0a1z6vgOAV82uN5+/zG12hMSJN2bGmGPW2pb5z9MzBgBA7q43J4yDqL4+u+MAEADLHXJ2c705w9QAgMDJZMg5FFr8Dl4olJwbkQ2GqQEABSOTIWc315sTxgDgU+w0lVomQ85urjdnmBoAfCgfM3/9LJMhZ2ZTAwCWJa8zf324+UwmQ85urjcnjOENPvxlB9yU15m/Ptx8JtMhZ7cK2RDG8AYf/rIDbmKnqcX5rcQpYQwAPsROU4vzW4lTwhgAfIidppbmp9rphDEA+JDfhmGxOMIYAHzIb8OwWBzrjOEN7DQFeBe/n45hnTEAIDNsPpNzRW43AJCU/GVebPkSv+yAe3p73W5B4BHG8AZ+2QEUMIapAQBwGWEMAIDLCGMAAFxGGLuBTREAAHMQxm5gUwQAwByEMQAALiOMAQBwGWEMAIDLCGMAAFxGGAMAshaPSwcP3ryD1MGDyeexNMphAgCyEo9Le/dKHR3S2FjyuYEB6fBh6YUX2NIxHfSM3cAOKAAC5Mknbw7iWWNjyeeffNKddvkJYeyG3t7k3p+pHmyaAMBHjhy5NYhnjY1JzzyT3/b4EWEMAMjKpUvZHQdhDADI0po12R0HYQwAyNK+fVJp6cLHSkulxx/Pb3v8iDAGAI/z+rKh/fulLVtuDeTS0uTz+/e70y4/IYyBHPP6hRTeNrts6PDh5HIha28sG9q71xs/R5FIcvnSgQM3/5wfOMCypnQZa60rX7ilpcW2tra68rWBfFlo/aV0o8fAhQpLOXgwGbwLzVYuLU0G3qFD+W8XMmOMOWatbZn/PD1jIIdYf4lssWyoMBDGQA5xIUW2WDZUGAhjIIe4kCJbLBsqDIQxkENcSJEtlg0VBsIYyCEupMgWy4YKA2EM5BAXUmTLyWVDLLPzLpY2ATkWjydnTT/zTPIe8erV0o4d0qlT0uXLyaHqffuSwcwyJ+QKy+y8gaVNgEsikeQ60FhMGhpK7pD58svJYPZiAQcEE8vsvI0wBvKICyLcwjI7b0srjI0x9xtjThtj2o0xn1vkdW83xiSMMb/jXBOB4OCCCLewzM7blgxjY0xY0lckvU/SDkkPGWN2pHjdlyT92OlGAkHBBRFuYZmdt6XTM75HUru19py1dkLStyR9cIHX/StJL0iKOdg+IFC4IMItLLPztnTCuFFS95yPe2aeu84Y0yjpQ5Keda5pQPBwQYRbWGbnbemEsVngufnrob4s6bPW2sSin8iYR40xrcaY1v7+/nTbCAQGF0S4hW0OvW3JdcbGmN+Q9MfW2vfOfPxHkmSt/c9zXtOpG6FdI+mapEettd9N9XlZZ4xCNX/d8Zo1yR4x64yB4Eu1zjidMC6SdEbSuyRdkPSKpI9aa0+leP03JP3AWvs/F/u8hDEAoNBkXPTDWjsl6dNKzpJ+XdK3rbWnjDGPGWMec76pAIBcoiym91AOEwAKCGUx3UU5TADAolXgTp+WvvhFd9pV6Ao2jBmmAVCIFqsCNzWVDGuug/lXkGE8O0xz+HCySD/F+gEUiqWqvCUS1Eh3Q0GGMcX684+RCMAb0qnyRo30/CvIMKZYf34xEgF4x759S7+GGun5V5BhTLH+/GIkAkHi91Ge/fulcHjx11AjPf8KMowp1p9fjEQgKIIwyhOJLB7I1Eh3R0GGMcX684uRCPheNCoZo0iF0WunjEbHjKxuPDrHor4a5fl3/0667TZqpHtJQYYxxfrzi5EI+F5f36KHo+rz1SgPm0Z4T0GGMT+I+cVIBAqFn0Z5IhHp0CEpFksuZ4rFkh9z/XMH5TCRc5Tfg++ZhXaSnfcSWdXWJkMNSIVymHANIxEoBIzyIBv0jAFgKWn0jHfttLy5xJIKsmfs9/WAAPyDIEY2itxuQK4sdJ9ydj3gCy/wiwPAWVxPkI3A9oyp+gTAMfX12R0HlhDYMKbqEwDH9PYmy22levT2ut1C+Fxgw5iqTwAAvwhsGFP1CQDgF4ENY6o+AQD8IrBhTP1pAIBfBDaMqfoEAPCLwIaxRCF0AJAogOQHgS36AQCgAJJfBLpnDKDARKPJOtKpHtGo2y3MOwog+QNhDCA4+vqyOx5AFEDyB8IYAAKMAkj+QBgDQIBRAMkfCGMACDAKIPkDYQwAAUYBJH8gjAEgwCiA5A+EMQB4mBMFOyiA5H2EMYDgqK/P7rjHzBbsOHw4WajD2hsFO/bupYJWkBDGAIKjtzeZWKkevb1ut3BZCr5gRwEVcSGMAcCjFivY0TkW1aH/GPCgKqAiLoQxAHjUYgU5oiqcoCoEhLFHsKsKgPkoyFE4CGMPYJIGgIUsVrADwUIYe0DBT9IAsKDFCnYgWAhjD2BXFQQNt12csVjBDgSLsda68oVbWlpsa2urK1/ba0Kh5ND0YscTify1B8jGQpvZSzfKL1L1ySHGLP0al67vjgng/9EYc8xa2zL/eXrGHsCuKggSbrsUiDysAZ6uC1YRl8UQxh7ArioIEm675Inb1cZyvAY4Hpf21PaqrNTK6MajrNRq106r+LD/irgshjD2gFSTNCRpclKamOBeG/yDzezzJGDVxuYrtBEWwtgDZidp/Jt/I4XDNx9LJKQvf5klTvAPbrvACYU2wkIYz+PWLNBIRCopkYqLbz0W1HeCCCZuu8AJhTbCQhjP4XbxjUJ7J+gVLMNxFpvZwwmFNsJCGM/h9j2KQnsn6AVuvwELIjazhxMKbYSFdcZz1NYmL8SLHY/Fgvv1C9HBg8ngXWhEorQ0GSCHDuW/XYDn5XgNcFDXq7POOA1u90wL7Z2gF3BrAMhQjpdWFdoICz3jOdzumQb1naCXUf0MQD7RM06D2z3TQnsn6AWFNkkEgDfRM56Dnmnh4Z4xgmhyclKTk5Oampq6/rDWau71PhwOKxwOq6ioSEVFRSopKVFRUZGLrS4MqXrGhPE88Xhy1vQzzyTvEa9Zk+wR799PEAcRb8DgV9ZajYyMaHh4WCMjIxobG9Po6KjGxsaUyPDeSlFRkUpLS1VaWqqysjJVVFQoEomorKxMJp0JW1gSYQykwBsw+EEikdDQ0JCuXLmioaEhxeNxTU9PS0r2cmcDdDZMi4uLVVRUdP3P+WE6PT19U895YmJCY2Nj1x+jo6M3ff5IJKKqqipVV1ersrJSoRB3OTNBGAMeN/um4MiRG28K9u3jTUEhGx8fVywW06VLl3T16lVNT08rFAqpsrJSFRUVOe25zva84/G44vG4rl69quHhYVlrFQqFVFVVpZqaGtXW1qp4odKBWBBhDHgYw+WYNTk5qb6+PvX392toaEiSFIlEVF1drerqaq1atUrh+UXs82RqakqDg4MaHBzUpUuXNDo6KmOMqqqqVFdXp7q6Otfa5hepwpi79YAHpFP9jYlkwTY0NKSLFy+qv79f09PTikQi2rRpk+rq6lRWVuZ28yQl7ynX1NSopqZGW7duVTweV39/v/r7+3X69Gm1t7ervr5eDQ0NivDucVnoGQMe4PYad7jDWqtYLKbu7m7F43EVFRUpGo1q7dq1Ki8vd7t5y3L16lVdvHhRsVhM09PTWrVqlTZs2KDVq1e73TRPoWcMeJjb1d+QX9Za9fX1qaurS9euXVN5ebmam5t9PcxbWVmpyspKbdmyRX19feru7taJEydUUVGhDRs2aM2aNczIXgRhDHjAmjWL94wpPhIcAwMD6ujo0OjoqCKRiHbu3KmamprABFVxcbGamprU0NBw/Q3Ha6+9poqKCm3dulWrVq1yu4meRBgDHrBv3+LFR6hL7n8jIyPq6OjQ5cuXtXLlSu3atSvQvcVQKKS1a9cqGo2qr69PnZ2d+vWvf626ujpt3rxZpanKHRYo7hkDHsBs6uCanp7W+fPn1d3drXA4rI0bN6qxsTGwIZxKIpFQd3e3urq6JEmbN28uyPNAbWrAw6hLHkzDw8NqbW1VV1eXotGo7r33XjU1NRVcAEm6/kbk3nvvVXV1tdrb23X8+HFdu3bN7aZ5Aj1jAHCYtVbnz59XV1eXSkpK1NzczKziefr6+nT27FlNT09r69atamhocLtJecFsagDIg4mJCb3++uu6cuWKotGotm7dygYMC6ivr1d1dbXeeOMNnTlzRoODg2pubvbtbPJs8RMCAA65evWqTp06pcnJSd12222KRqNuN8nTSkpKtHv3bnV1den8+fOKx+PatWuXVq5c6XbT8i6te8bGmPuNMaeNMe3GmM8tcPx3jTEnZh7/aIy53fmmAoB3xWIxHT9+XMYY3XXXXQRxmowx2rBhg/bs2aOpqSn96le/0uDgoNvNyrslw9gYE5b0FUnvk7RD0kPGmB3zXtYp6bettXskfUHSc043FAC8qqenR21tbaqsrNTdd99NKcgMVFdX66677lJJSYlOnDihWIGVnEunZ3yPpHZr7Tlr7YSkb0n64NwXWGv/0Vp7ZebDlyQ1OdtMAPCmjo4Otbe3q7a2Vnv27GEHoyyUlpbqrrvuUmVlpdra2tTT0+N2k/ImnXvGjZK653zcI+neRV7/SUn/K5tGAYAftLe3q6enR42Njdq6dWtBLllyWlFRkfbs2aPXX39d7e3tkqSmphv9u4mpaf20rU8/P9OvkxeG1NEf10RiWiXhkLbURrS7cZV+a3ut3rOzXsVh/6zeTSeMF/rpWnA9lDHmnykZxvelOP6opEclaf369Wk2EQC859y5c+rp6VFTU5O2bt3qdnMCJRQKaceOHWpra1N7e7uMMaqLrtXXX+zU8y92anNtuT6we60eune9ttVFVFYc1uhkQmdjcZ3sGdQ3/+m8Dn3/lD5x3yZ96r5NKvJBKC+5ztgY8xuS/tha+96Zj/9Ikqy1/3ne6/ZI+htJ77PWnlnqC7POGIBfnT9/XufPn1dDQ4O2b9/udnMCa3p6Wm1tbTp+pkvfaBvX2rUN+vwDO7S9vmLJf3umb1hf+EGbBq9N6umP3K5tafybfMimAtcrkrYZYzYZY0okPSjpe/M++XpJ35H0sXSCOMjicengwZurKB08mHwegP/19vbq/Pnzikaj2rZtm9vNCbRQKKTR8qi++PfdekfNpP7kQ9vSCmJJ2l5foW9+4h49dM96PfTVl3Tszcs5bm120qrAZYx5v6QvSwpLet5a+0VjzGOSZK191hjzNUn/h6Q3Z/7J1ELJP1cQe8bUFwaCbWhoSMePH1k33V8AAB1HSURBVFdVVZX27NnDPeIcO9s3rAefe0mHP7xTldcuaHx8XHfeeeey93r+2emYPvPXr+roI3td7yFnVZvaWvsja+12a+0Wa+0XZ5571lr77MzfP2WtrbbW3jHzWDSIg+rJJ28NYin5cUdH8jjgS9GoZEzqRwGsqR0dHdVrr72msrIy7dy5kyDOscnEtP7w28f1mfc26107G7R7926FQiGdPHlSU1NTy/pc72yu0xPvbtYT335Vk4npHLU4O96/q+0jR44svAWelHz+mWfy2x7AMX192R33udl7l9Za7d69m/KWefD1FztVvbJED759naTksqddu3ZpfHxcb7zxxrI/30P3rFPVymJ9/cVOp5vqCMLYQZcuZXccgDd1dnZqeHhYzc3NKisrc7s5gTcxNa2vv9ipzz+w46YRiMrKSm3evFkDAwO6cOHCsj6nMUb//gM79PyLnZ7sHRPGDlqzJrvjALzn8uXL6u7uVkNDg2pra91uTkH4aVufNteULzhZq6mpSWvWrNHJkx36oz+KL2uybHO0QhtryvWTU94bySGMHbRvX3Ky1kJKS6XHH89vewBkJ5FI6PTp0yovL9eWLVvcbk7B+PmZfj2wZ+2Cx4wxamq6Tfv2Fenpp09rYMDKWmlgQDp8ODmJdrFA/hd71uoXZ/tz1PLMEcYO2r8/OWt6fiDPzqbev9+ddgHITGdnp8bHxwt6az83nLwwpN1NVSmPf/nLxbp4casmJoYl3RiuTmey7K7GVTrRM+Rga51BGDsoEkkuXzpw4OZ1xgcOsKwJ8Jvh4WFduHBBDQ0NqqysdLs5BaWjP65tdakvmEeOSOPjdZLWKLlP0Y2Zs0tNlt1eX6FzA94r/MCUQIdFItKhQ8kHAP86e/asiouLtXnzZrebUnAmEtMqK049EnFjMuw2JetSnVNyU8H5x29VWhzW+BQTuAD4UX19dsd9ZmBgQFevXtXmzZtZxuSCknBIo5OJlMdvTIYtVXKTwJik+ALHbzU2mdCKIu9Fn/daBMB7ensla1M/envdbqFjrLXq7OzUypUrVR+wNxl+saU2orOx1EPJN0+WXSepWMne8dKTZc/0DWtzjffuGRLGADBHLBbTyMiINm3aRJUtl+xuXKWTPYMpj988WbZI0npJl7VixeCSk2VfuzCkPU2rHG5x9ghjAJijq6tLkUhENTU1bjelYP3W9lr94MRbKY/PnyxrTKOqqor1+7/fveRk2e+feEu/uc1768UJYwCYceXKFY2MjKipqYlesYvevaNe5wZGdKZvOOVrZifLxmLS9HRIv/51ox588JLC4dGU/+Z077DOD4zoPTu9d/uBMIansSUl8unChQsqLi5WXV2d200paCVFIX3yvk36wg+S9cDT0dDQoFAopJ6engWPW2v1n37Ypk/ct0nFYe9Fn/daBMyY3ZLy8OFkdZ3lVNkBlmtsbEwDAwPXL+pw16fu26TBa5P61ivdab2+pKREdXV16u3tVSJx60zsoy93a/DapD513yanm+oI5uzDs9LZkpL13HBKLBaTJK1du3AZRq+amJrWT9v69PMz/Tp5YUgd/XFNJKZVEg5pS21EuxtX6be21+o9O+s92SNMpSgc0tMfuV0PPveS1q4q1Tublx6tiEaj6u3t1aVLl24a3fjZ6Zie/ulpHX1kr4o8eg5MukMATmtpabGtra2ufG34Q21tsie82PGZ6yeQtdbWVoXDYd15551uNyUtk4nkzkbPv9ipzbXl+sDutdrdVKVtdRGVFYc1OpnQ2VhcJ3sG9YMTb6lzYESfuG+TPnXfJs8G0kKOvXlZf/AXx/TEu5v10D3rFr2Xb63VSy+9pEgkot27d8taq6Mvd+vpn57Wn3+sRXdvqM5jyxdmjDlmrW255XnCGF4VCiWHphc7vsBoFLBsIyMjeuWVV7Rt2zY1Nja63Zwlne0b1h9++7iqV5bo8w/sWHB3o/nO9A3rCz9o0+C1ST39kdu1LY1/4xVn+4b1xLdfVdXK4iX/vx0dHerp6dGazbv1pZ+c9dz/N1UYM0wNz1qzZvGeMVtSwikDMz9oftgi8dibl/XoN4/pM+9t1oNvX7ynONf2+gp98xP36OjL3Xroqy/pzz92t+7esDrHrXXGtvoKfWffO/T1Fzv1e1/7pTbVlOuBPWu1q3GVttdXqLQ4rLHJhM70DeuVzlH91Y9e09CKmB67/y590icjAYQxPGvfvuRkrfn3jCW2pISzrly5ooqKCpWUlLjdlEWd7RvWo988pv/6kdvTuoc6nzFGH713vRqqSvUHf3FMRx/Z65ke41KKwyE99ttb9Mn7Nuknp/r0i7P9Ovpyt84NxDU+Na0VRSFtrolod2OlHrijSe+9e5t27/TPtpcMU8OzZmdTz5/ENbslJTthwQmJREIvvvii1q1b5+lNISYT0/rQkf9Pv3vvBj10z/qsP99f/bJLR1/u0nf2vcNXE7vS0dbWpsHBQb3jHe9wuym3SDVMHazvAAKFLSmRD0NDQ7LWqqoq9f65XvD1FztVvbJED759nSOf76F71qlqZbG+/mKnI5/PS6qrqzUxMaGRkRG3m5I2whieNrfKTiKR/PPQIYIYzhkaGpIxRqtWea9e8ayJqeTM6c8/sMOxymDGGP37D+zQ8y92ajLhvS0FszH7vRweTl3By2sIYwAFbWRkRGVlZQqHU++f67aftvVpc035orOIM6lW1xyt0Maacv3kVF8OWu2e2e9n3EeVgQhjAAUtHo8r4vGhlp+f6dcDe1IXI8mmWt2/2LNWvzjbn4NWu8cYo/LycnrGAOAHU1NTGhsb83wYn7wwpN1Nqe9pL16tzurhh0/qzjvvVFlZmUKhkMrKynTnnXfq6NGjaq5bqRM9Qzn+H+RfJBLx1T1jljYBKFijo8kdflauXOlySxbX0R/XtrrUbxiOHFl4CaAkjY0Zffe7UVl7fM5zYzp+/LgeffRRhUrKVPvo12/6N0EosVlWVqapqSlNTU2pqMj7Uef9FgIeFI8neyNHjkiXLiULkOzbl9zU3OOdLMwxMTEhSZ5fXzyRmFZZcep72pcuLf7vrV24uEc8HpfMNVVNS5///Of1H/740C0lNh+6d/2CJTa/+U/ndej7pzxbYnPFihWSpPHxccIYCKKF1j/P3p974QWWXfnJ+Pi4pBsXbq8qCYc0OplQ+YqFL9lLVauTUqe1KSqRnZrQn/xf/7d+au7Stg0N+stP3bvgZLHyFUW6Y12V7lhXpY/9xsbrJTZ/eOItT5WclKTS0lJJyVGA8vJyl1uzNG+9lQF8IJ3dpOAP4+PjMsZ4vme8pTais7HUs7D27UsWw1nYqKQjKf9tcc16JYYHtOpDB9Xxk/+hr/3eHWnVupZulNh86J71euirL+nYm5fT+nf5MPs9nR398DrCGFimxe/PSc88k9/2IHOJRELhcNixtbu5srtxlU72DKY8vn9/sirdrYE8KqlD0lMp/23ZlrcrXFGrgR8+rbFTf6+/+Zu/WVbbZktsPvV/3q4/+ItjOtvnjRnMs0vVpqf9sYaaMEbmolHJmNSPaNTtFubEUvfnljoO75ienvZ8EEvSb22v1Q9OvJXy+NxqdeHwZUkJSTFJX5K0V1KKWcWhsCrf/r9r5LW/11jnrxSPx/WlL30poza+s7lOT7y7WU98+1VPFBEJhZLxlvDJ1m6EMTLXt0ShgKWO+9RSu0Wxm5R/TE9PX79oe9m7d9Tr3MCIzizS65ytVldc3KjkdKB6SYeUMoglVf/270uhsC7/P39+/bnTp09n3E4vldic/b729/tjDbX3fwoBj1ns/hy7SfmLtdYXYVxSFNIn79ukL/ygTUtt7jM7KW1JoSJV3PWAho/9UJq+0XscS3UPJg1eKrE5O+Lhl8If3v8pBDwm1f252d2k9u93p11YvlAo5Jt7ip+6b5MGr03qW690L/q6dGeGr/7f/kA2ManBf/jvNz1fOucH288lNmfftGzcuNHVdqSLMAaWid2kgiMcDvvmnmJROKSnP3K7nvrxaf3sdCzl62677bYlP1fpprtUvuuf62rr30r25jcjzc3NkvxfYnP2TZYfRj4kwhjICLtJBYOfwliSttVX6LmH79Zn/vpV/dUvuxYcsj5w4IAqKlIvTYrc/l7VfOAPlRge0GjHKzcdq6io0Gc/+1lJ2S3h29W4yvUSm7PfVy9vADIXYQygYIXDYVlrfRXId29YraOP7NXRl7v08PMv3zKp68Mf/vCCM8SLazao7iP/UZHb71ff0X+rcEWNJge6bnqNMUYf/vCHJWW3hG97fYXODbi7Y5JfCrrMogIXgII1t2Si1+tTz7WtvkLf2fcOff3FTv3e136pTTXlemDPWu1qXKXt9RU6/ORTeuLAZzW1slYl0a0qv+03VVTdoOHWv9XVV74r2WmZomLZyRuTvVauXKmnnnrqerGMbJbwlRaHNT7l7r14v5Q6nUUYI3P19YsvX6qvz19bgAzMLZnopzCWpOJwSI/99hZ98r5N+smpPv3ibL+OvtytcwNxjU81KPrYNzTW36Wxi2c0/Ksf6NrZl26aNW2nJmWKV8hOJv/vTzzxhB555JHrx5cqsbnYEr6xyYRWFLk78EoYo3D09rrdAiArc8PYr4rDIX1gz1p9YIH9jr/61a/qM5/5HwpNT98UxJI0dblHq9Y1a3qgU0899dRNQSwll/AdPrzwUPVSS/jO9A1rc427EyhGR0cVCoV8M0zNPWMABaukpEThcFjXrl1zuyk58cgjjygWi+m5557THXfcobKyMhljVFZWpsjkFT38h59Xf3//LUEsZbeE77ULQ9rTtMrh/83yjIyMaOXKlb6osCYRxgAKmDFGkUjEN4UhMrFixQo99NBD+vWvf61r165penpa165d03878Kh6ixtSDuNms4Tv+yfe0m9uq83R/yg98XjcF7s1zSKMARS0iooKxePxJStbBc1ySmwuZwnf6d5hnR8Y0Xt2ujdnZGpqSuPj44QxAPhFRUWFEolEYIeqU1lOic10WWv1n37Ypk/ct0nFYffiZXAwucNVZWWla21YLsIYQEGbvWDPXsALSbolNtN19OVuDV6b1Kfu2+TI58vU4OCgQqEQYQwAflFWVqaysjJdvnzZ7abkXbolNtPxs9MxPf3T03r6I7eryMVesZQM41WrVvmmFKZEGAOAVq9ercHBQd9sGuGkdEpsLsZaq7/6ZZc+89ev6s8/1qJt9alLcebDxMSE4vG4qqqqXG3HchHGAAre6tWrlUgkCnKoWlq6xGYqp3uH9fDzL+voy106+she3b2hOsctXdrs/sW1te7O5l4uin4AKHjV1dUqKipSLBbT6tWr3W6OK5YqsVlaHNbYZEJn+ob12oUhff/EWzo/MKJP3rdJn7xvk+tD07P6+/tVXl7uu4pqhDGAghcKhVRbW6tYLKZt27b5Zqcfpy1eYnNaK4pC2lwT0Z6mVfr9d2zUu3fUuzprer7x8XENDg5q0yZ3J5BlgjAGAEnRaFRvvfWWBgYGVF/gddUXK7HpZb0zJXrr6upcbsnyeectDQC4qLKyUqWlpbp48aLbTUEGrLW6ePGiVq9erbKyMrebs2yEMRwRj0sHD95cNu/gweTzcBbnOjeMMWpqatLQ0JCuXr3qdnOwTAMDAxofH1dDQ4PbTckIYYysxePS3r3JHV4GBiRrk38ePpx8npBwDuc6t9auXauioiL19PS43RQsU09Pj0pLS7Vmsb0dPYwwRtaefFLq6Lh1q7WxseTzTz7pTruCiHOdW+FwWA0NDerv79fo6KjbzUGarly5oqGhIa1bt843uzTNRxgja0eOLLznqZR8/pln8tueIONc515jY6OMMTp//rzbTUGaOjs7tWLFCq1d668JZ3MRxsjapUvZHUf6ONe5t2LFCq1bt059fX2B3loxKC5duqSrV69qw4YNvip/OZ9/Ww7PWOoWjU9v4XgS5zo/1q1bp+LiYp07d87tpmAR09PT6ujoUFlZma97xRJhDAfs2yeVli58rLRUevzx/LYnyDjX+VFUVKSNGzfqypUr18srwnu6u7t17do1bdu2zbf3imcRxsja/v3Sli23hkRpafL5/fvdaVcQca7zp6GhQRUVFTp79qwmJyfdbg7mGRsb05tvvqna2tpAlDAljJG1SER66SXpwIGb174eOJB8PhJxu4XBwbnOH2OMmpubNTk5qY6ODrebgzmstTp9+rSMMdq6davbzXGEWe52WU5paWmxra2trnxtAEjXuXPn1NXVpd27d/t2DWvQ9PT0qL29Xdu3b/ddkQ9jzDFrbcv85+kZA8AiNm7cqEgkojfeeENjqdaVIW/i8bjOnTunmpoa3wXxYghjAFhEKBTSzp07NT09rba2Nrk1mghpampKbW1tKioqUnNzs9vNcRRhDABLKCsrU3Nzs65evcr9Y5dYa/X6669rdHRUO3bsUHFxsdtNchRbKAJAGurq6nT16lX19PSorKxMjY2NbjepoJw7d06XLl3S9u3bVVVV5XZzHEcYA0CatmzZorGxMZ09e1YrVqxQTU2N200qCBcvXlR3d7caGxsDdZ94rrSGqY0x9xtjThtj2o0xn1vguDHG/OnM8RPGmLucbyoAuMsYo7e97W2qrKxUW1ubhoaG3G5S4PX19enMmTNas2ZNYJYxLWTJMDbGhCV9RdL7JO2Q9JAxZse8l71P0raZx6OSKFcPIJDC4bB27dql0tJSnThxgkDOoYGBAb3xxhuqqqrSzp07fV9lazHp9IzvkdRurT1nrZ2Q9C1JH5z3mg9K+qZNeklSlTHG34VCASCFkpIS3XHHHVqxYoVOnDihwcFBt5sUOP39/Tp16pQqKiq0e/duX28CkY50/neNkrrnfNwz89xyXwMAgTE3kE+ePKlLbJnlmIsXL+rUqVOqrKzUnj17FA6H3W5SzqUTxguNC8xfaJfOa2SMedQY02qMaaX4OgC/mw3klStX6rXXXtOFCxfcbpLvnT9//vo94j179qioqDDmGacTxj2S1s35uEnSxQxeI2vtc9baFmttS21t7XLbCgCeMxvIq1ev1tmzZ9XR0UFhkAwkEgm1tbXp/Pnzikaj2rVrV0H0iGelE8avSNpmjNlkjCmR9KCk7817zfckPTwzq3qvpCFr7VsOtxUAPGl2UldjY6O6u7v16quvamJiwu1m+cbo6Kh+9atfqb+/X5s3b9Ztt90W6MlaC1my/2+tnTLGfFrSjyWFJT1vrT1ljHls5vizkn4k6f2S2iVdk/Tx3DUZALzHGKNt27apoqJCZ86cUWtrq972trepurra7aZ5WiwW05kzZ2SM0Z49ewr2fLFrEwA4bGRkRG1tbRoZGdG6deu0cePGghpyTcfk5KTOnj2rWCymyspK7dixQ6XzN+oOoFS7NhXGnXEAyKPy8nLddddd6ujoUHd3twYGBtTc3BzIMo6ZGBgY0JkzZzQ5OalNmzZp/fr1BTcsPR9hDAA5EA6HtX37dtXV1en06dM6fvy41q5dq02bNqmkpMTt5rni2rVram9v1+XLl1VeXq49e/YoEom43SxPIIwBIIeqqqrU0tKi8+fPq6enR7FYTOvXr1dTU1PBDF1PTU2pq6tL3d3dCoVC2rp1qxobGwu+NzwXYQwAORYOh7VlyxY1NDTo3Llz6uzs1MWLF7V+/XqtXbs2sNWlpqam1NPTo56eHk1NTSkajWrz5s0FOzKwGMIYAPKkrKxMO3fu1NDQkM6dO6ezZ8/qzTffVFNTkxoaGgJT4GJiYkIXL168HsI1NTXauHEjQ9KLCMZ3HgB8ZNWqVbrzzjs1ODiorq4unTt3Tl1dXaqrq1NDQ4NvQ2toaEgXLlxQf3+/rLWE8DIQxgDgkqqqKlVVVWl4eFg9PT3q7e3VxYsXVVFRoWg0qtraWs8P6Y6OjioWiykWi2lkZERFRUVqbGxUY2OjysrK3G6eb7DOGAA8YmpqSn19fXrrrbcUj8clJXvRtbW1WrNmjSfCzVqreDyuK1euaGBgQFevXpWUbGd9fb3q6+sLZmJaJlhnDAAeN7dXOTIyooGBAfX396u9vV3t7e1asWLF9d70qlWrVFZWlvMZybPhOzw8rKGhIV2+fFmTk5OSpIqKCm3ZskW1tbUFUbAjlwhjAPCg8vJylZeXa8OGDRodHdWVK1d05coVXb58WX19fZKSs7TLy8sViURUXl6u0tJSrVixQqWlpcuaDGatVSKR0NjYmEZHR68/RkZGFI/HNT09LSm5Kcbq1au1evVqVVdXe34I3U8IYwDwuLKyMpWVlamhoUFSstzm1atXr4dlLBbT1NTUTf8mHA4rHA6rqKjo+t8lXd9RylqrqakpTU5Oampq6padpkpKSrRy5Uo1NjaqoqJClZWV9H5ziDAGAJ+Z7TXPNTExobGxMY2Pj1//M5FIKJFIaGpqSolEQlJyQ4vZx4oVK1RcXHz9UVJScj34g7LMyi842wAQACUlJQwb+1gwy74AAOAjhDEAAC4jjAEAcBlhDACAywhjAABcRhgDAOAywhgAAJcRxgAAuIwwBgDAZYQxAAAuI4wBAHAZYQwAgMsIYwAAXEYYAwDgMsIYAACXEcYAALiMMAYAwGWEMQAALjPWWne+sDH9kt7M8J/XSBpwsDmFjHPpHM6lcziXzuJ8Oifbc7nBWls7/0nXwjgbxphWa22L2+0IAs6lcziXzuFcOovz6ZxcnUuGqQEAcBlhDACAy/waxs+53YAA4Vw6h3PpHM6lszifzsnJufTlPWMAAILErz1jAAACw7NhbIy53xhz2hjTboz53ALHjTHmT2eOnzDG3OVGO/0ijfP5uzPn8YQx5h+NMbe70U4/WOpcznnd240xCWPM7+SzfX6Szrk0xrzTGHPcGHPKGPMP+W6jX6TxO77KGPN9Y8yrM+fy42600w+MMc8bY2LGmNdSHHc+f6y1nntICkvqkLRZUomkVyXtmPea90v6X5KMpL2Sful2u736SPN8vkNS9czf38f5zPxcznnd/yvpR5J+x+12e/GR5s9llaQ2SetnPq5zu91efKR5Lv+tpC/N/L1W0mVJJW633YsPSb8l6S5Jr6U47nj+eLVnfI+kdmvtOWvthKRvSfrgvNd8UNI3bdJLkqqMMWvz3VCfWPJ8Wmv/0Vp7ZebDlyQ15bmNfpHOz6Yk/StJL0iK5bNxPpPOufyopO9Ya7skyVrL+VxYOufSSqowxhhJESXDeCq/zfQHa+3PlTw/qTieP14N40ZJ3XM+7pl5brmvQdJyz9UnlXzXh1steS6NMY2SPiTp2Ty2y4/S+bncLqnaGPMzY8wxY8zDeWudv6RzLv9M0tskXZR0UtK/ttZO56d5geN4/hRl1ZzcMQs8N3/adzqvQVLa58oY88+UDOP7ctoi/0rnXH5Z0mettYlkJwQppHMuiyTdLeldksok/ZMx5iVr7ZlcN85n0jmX75V0XNI/l7RF0k+NMb+w1l7NdeMCyPH88WoY90haN+fjJiXfzS33NUhK61wZY/ZI+pqk91lrL+WpbX6TzrlskfStmSCukfR+Y8yUtfa7+Wmib6T7ez5grR2RNGKM+bmk2yURxjdL51x+XNJ/scmbnu3GmE5Jt0l6OT9NDBTH88erw9SvSNpmjNlkjCmR9KCk7817zfckPTwzq22vpCFr7Vv5bqhPLHk+jTHrJX1H0sfodSxqyXNprd1krd1ord0o6X9K2kcQLyid3/O/lfSbxpgiY8xKSfdKej3P7fSDdM5ll5IjDDLG1EtqlnQur60MDsfzx5M9Y2vtlDHm05J+rOQsweettaeMMY/NHH9WyVmq75fULumaku/6sIA0z+d/kLRG0pGZHt2UpbD8LdI8l0hDOufSWvu6MebvJJ2QNC3pa9baBZebFLI0fy6/IOkbxpiTSg6zftZay05OCzDGHJX0Tkk1xpgeSQclFUu5yx8qcAEA4DKvDlMDAFAwCGMAAFxGGAMA4DLCGAAAlxHGAAC4jDAGAMBlhDEAAC4jjAEAcNn/D/8K1brZIEioAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediccion realizada para etiqueta del punto = 0 (circulo azul)\n"
     ]
    }
   ],
   "source": [
    "k = 3  # hyper-parameter\n",
    "N = 100\n",
    "X = np.random.rand(N, 2) # random dataset\n",
    "Y = np.array(np.random.rand(N) < 0.4, dtype=int).reshape(N, 1) # random dataset\n",
    "x = np.random.rand(1, 2) # query point\n",
    "\n",
    "# performing the search\n",
    "plot_knn(X, Y, k, x)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='data_exploration'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Exploración de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "A continuación se carga el conjunto de datos a utilizar, a través del sub-módulo `datasets` de `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "digits_dict = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print(digits_dict[\"DESCR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "digits_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "digits_dict[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "A continuación se crea dataframe declarado como `digits` con los datos de `digits_dict` tal que tenga 65 columnas, las 64\n",
    "primeras a la representación de la imagen en escala de grises (0-blanco, 255-negro) y la última correspondiente al dígito (`target`) con el nombre _target_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "digits = (\n",
    "    pd.DataFrame(\n",
    "        digits_dict[\"data\"],\n",
    "    )\n",
    "    .rename(columns=lambda x: f\"c{x:02d}\")\n",
    "    .assign(target=digits_dict[\"target\"])\n",
    "    .astype(int)\n",
    ")\n",
    "digits.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Ejercicio 1\n",
    "\n",
    "**_(10 puntos)_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "**Análisis exploratorio:** Realiza tu análisis exploratorio, no debes olvidar nada! Recuerda, cada análisis debe responder una pregunta.\n",
    "\n",
    "Algunas sugerencias:\n",
    "\n",
    "* ¿Cómo se distribuyen los datos?\n",
    "* ¿Cuánta memoria estoy utilizando?\n",
    "* ¿Qué tipo de datos son?\n",
    "* ¿Cuántos registros por clase hay?\n",
    "* ¿Hay registros que no se correspondan con tu conocimiento previo de los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "digits.describe().T[['min','max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits.info(verbose = False, memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits.assign(count=np.ones(len(digits[\"target\"]))).groupby('target').sum()['count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "**Respuestas:** \n",
    "\n",
    "_Los datos estan en un dataframe de (1797,65) descrito en el enunciado. Los valores de cXX van desde 0 hasta 16. La memoria utilizada es de  456.4 KB, los datos son del tipo int32 y la cantidad de registros por clase es la calculada en la celda anterior. Me sorprende que los datos vayan de 0 a 16 ya que al ser datos de una imagen en RGB deberían ir de 0 a 250._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Ejercicio 2\n",
    "\n",
    "**_(10 puntos)_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "**Visualización:** Para visualizar los datos utilizaremos el método `imshow` de `matplotlib`. Resulta necesario convertir el arreglo desde las dimensiones (1,64)  a (8,8) para que la imagen sea cuadrada y pueda distinguirse el dígito. Superpondremos además el label correspondiente al dígito, mediante el método `text`. Esto nos permitirá comparar la imagen generada con la etiqueta asociada a los valores. Realizaremos lo anterior para los primeros 25 datos del archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "digits_dict[\"images\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Visualiza imágenes de los dígitos utilizando la llave `images` de `digits_dict`. \n",
    "\n",
    "Sugerencia: Utiliza `plt.subplots` y el método `imshow`. Puedes hacer una grilla de varias imágenes al mismo tiempo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "nx, ny = 5, 5\n",
    "fig, axs = plt.subplots(nx, ny, figsize=(12, 12))\n",
    "for i in range(nx):\n",
    "    for j in range(ny):\n",
    "        axs[i][j].imshow(digits_dict[\"images\"][ny*i+j],cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='train_and_prediction'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Entrenamiento y Predicción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Se utilizará la implementación de `scikit-learn` llamada `KNeighborsClassifier` (el cual es un _estimator_) que se encuentra en `neighbors`.\n",
    "\n",
    "Utiliza la métrica por defecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "X = digits.drop(columns=\"target\").values\n",
    "y = digits[\"target\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Ejercicio 3\n",
    "\n",
    "**_(10 puntos)_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Entrenar utilizando todos los datos. Además, recuerda que `k` es un hiper-parámetro, por lo tanto prueba con distintos tipos `k` y obten el `score` desde el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "k_array = np.arange(1, 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "for k in k_array:\n",
    "    knn = KNeighborsClassifier(k)\n",
    "    knn.fit(X, y)\n",
    "    print('Utilizando todos los datos y k= {:.0f}'\n",
    "         .format(k),' se obtiene score= {:.4f}'\n",
    "         .format(knn.score(X, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "**Preguntas**\n",
    "\n",
    "* ¿Cuál fue la métrica utilizada?\n",
    "* ¿Por qué entrega estos resultados? En especial para k=1.\n",
    "* ¿Por qué no se normalizó o estandarizó la matriz de diseño?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "_La metrica utilizada es la que se da por defecto: **minkowski**. Para k=1 el score es perfecto ya que los datos que se ocupan para hacer fit son los mismos que se ocuparon para hacer training. No se normalizó o estandarizó la matriz de diseño pues aumentaría la complejidad._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Ejercicio 4\n",
    "\n",
    "\n",
    "**_(10 puntos)_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Divide los datos en _train_ y _test_ utilizando la función preferida del curso. Para reproducibilidad utiliza `random_state=42`. A continuación, vuelve a ajustar con los datos de _train_ y con los distintos valores de _k_, pero en esta ocasión calcula el _score_ con los datos de _test_.\n",
    "\n",
    "¿Qué modelo escoges?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "for k in k_array:\n",
    "    knn = KNeighborsClassifier(k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    print('Utilizando todos los datos y k= {:.0f}'\n",
    "         .format(k),' se obtiene score= {:.4f}'\n",
    "         .format(knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='model_selection'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "_Eligiría k=6 ya que es el que tiene mejor score._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Selección de Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Ejercicio 5\n",
    "\n",
    "**_(15 puntos)_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "\n",
    "**Curva de Validación**: Replica el ejemplo del siguiente [link](https://scikit-learn.org/stable/auto_examples/model_selection/plot_validation_curve.html#sphx-glr-auto-examples-model-selection-plot-validation-curve-py) pero con el modelo, parámetros y métrica adecuada.\n",
    "\n",
    "¿Qué podrías decir de la elección de `k`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "param_range = np.arange(1, 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train_scores, test_scores = validation_curve(KNeighborsClassifier(),X, y, param_name=\"n_neighbors\",cv=5, param_range=param_range, n_jobs=1)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"Validation Curve with KNN\")\n",
    "plt.xlabel(r\"$\\gamma$\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.0, 1.1)\n",
    "lw = 2\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"Validation Curve with KNN\")\n",
    "plt.xlabel(r\"$\\gamma$\")\n",
    "plt.ylabel(\"Score\")\n",
    "lw = 2\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "**Pregunta**\n",
    "\n",
    "* ¿Qué refleja este gráfico?\n",
    "* ¿Qué conclusiones puedes sacar a partir de él?\n",
    "* ¿Qué patrón se observa en los datos, en relación a los números pares e impares? ¿Porqué sucede esto?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "_El grafico muestra como varía el score máximo con k. Es claro que Training siempre esta por sobre Cros-validation. Se puede concluir que un número k menor es una buena opción ya que las curvan parecen ir decreciendo, en especifico para Training k=1 es el máximo score por lo visto en el ejercicio 3 y para Cros-validation parece ser k=2. Un patrón que se observa es que los valores van creciendo y decreciendo cuando cambian de par a impar, pero es no siempre. Esto se debe a que el algoritmo debe elegir entre empates cuando se tiene k par._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Ejercicio 6\n",
    "\n",
    "**_(15 puntos)_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "**Búsqueda de hiper-parámetros con validación cruzada:** Utiliza `sklearn.model_selection.GridSearchCV` para obtener la mejor estimación del parámetro _k_. Prueba con valores de _k_ desde 2 a 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "parameters = {'n_neighbors':np.arange(2, 100)}\n",
    "digits_gscv =  GridSearchCV(KNeighborsClassifier(), parameters, verbose=1, cv=5)\n",
    "digits_results = digits_gscv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Best params\n",
    "digits_results.best_params_['n_neighbors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "**Pregunta**\n",
    "\n",
    "* ¿Cuál es el mejor valor de _k_?\n",
    "* ¿Es consistente con lo obtenido en el ejercicio anterior?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "_El mejor valor fue k=2 y dado que en el ejercicio anterior no pude distinguir cual sería un buen valor, no se si son consistentes._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Ejercicio 7\n",
    "\n",
    "**_(10 puntos)_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "__Visualizando datos:__ A continuación se provee código para comparar las etiquetas predichas vs las etiquetas reales del conjunto de _test_. \n",
    "\n",
    "* Define la variable `best_knn` que corresponde al mejor estimador `KNeighborsClassifier` obtenido.\n",
    "* Ajusta el estimador anterior con los datos de entrenamiento.\n",
    "* Crea el arreglo `y_pred` prediciendo con los datos de test.\n",
    "\n",
    "_Hint:_ `digits_gscv.best_estimator_` te entrega una instancia `estimator` del mejor estimador encontrado por `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "best_knn = digits_gscv.best_estimator_\n",
    "best_knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "y_pred = best_knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Mostrar los datos correctos\n",
    "mask = (y_pred == y_test)\n",
    "X_aux = X_test[mask]\n",
    "y_aux_true = y_test[mask]\n",
    "y_aux_pred = y_pred[mask]\n",
    "\n",
    "# We'll plot the first 100 examples, randomly choosen\n",
    "nx, ny = 5, 5\n",
    "fig, ax = plt.subplots(nx, ny, figsize=(12,12))\n",
    "for i in range(nx):\n",
    "    for j in range(ny):\n",
    "        index = j + ny * i\n",
    "        data  = X_aux[index, :].reshape(8,8)\n",
    "        label_pred = str(int(y_aux_pred[index]))\n",
    "        label_true = str(int(y_aux_true[index]))\n",
    "        ax[i][j].imshow(data, interpolation='nearest', cmap='gray_r')\n",
    "        ax[i][j].text(0, 0, label_pred, horizontalalignment='center', verticalalignment='center', fontsize=10, color='green')\n",
    "        ax[i][j].text(7, 0, label_true, horizontalalignment='center', verticalalignment='center', fontsize=10, color='blue')\n",
    "        ax[i][j].get_xaxis().set_visible(False)\n",
    "        ax[i][j].get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Modifique el código anteriormente provisto para que muestre los dígitos incorrectamente etiquetados, cambiando apropiadamente la máscara. Cambie también el color de la etiqueta desde verde a rojo, para indicar una mala etiquetación. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Mostrar los datos incorrectos\n",
    "mask = (y_pred != y_test)\n",
    "X_aux = X_test[mask]\n",
    "y_aux_true = y_test[mask]\n",
    "y_aux_pred = y_pred[mask]\n",
    "\n",
    "ni = X_aux.shape[0]\n",
    "fig, ax = plt.subplots(1, ni, figsize=(12,12))\n",
    "for i in range(ni):\n",
    "    data  = X_aux[i, :].reshape(8,8)\n",
    "    label_pred = str(int(y_aux_pred[i]))\n",
    "    label_true = str(int(y_aux_true[i]))\n",
    "    ax[i].imshow(data, interpolation='nearest', cmap='gray_r')\n",
    "    ax[i].text(0, 0, label_pred, horizontalalignment='center', verticalalignment='center', fontsize=10, color='red')\n",
    "    ax[i].text(7, 0, label_true, horizontalalignment='center', verticalalignment='center', fontsize=10, color='blue')\n",
    "    ax[i].get_xaxis().set_visible(False)\n",
    "    ax[i].get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "**Pregunta**\n",
    "\n",
    "* Solo utilizando la inspección visual, ¿Por qué crees que falla en esos valores?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "_Visualmente la predicción falla pues los valores están mal dibujados y además son números similares (3 y 9, 1y 8, 0 y 6)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Ejercicio 8\n",
    "\n",
    "**_(10 puntos)_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "**Matriz de confusión:** Grafica la matriz de confusión.\n",
    "\n",
    "**Importante!** Al principio del curso se entregó una versión antigua de `scikit-learn`, por lo cual es importante que actualicen esta librearía a la última versión para hacer uso de `plot_confusion_matrix`. Hacerlo es tan fácil como ejecutar `conda update -n mat281 -c conda-forge scikit-learn` en la terminal de conda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "plot_confusion_matrix(best_knn, X_test, y_test, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "**Pregunta**\n",
    "\n",
    "* ¿Cuáles son las etiquetas con mejores y peores predicciones?\n",
    "* Con tu conocimiento previo del problema, ¿Por qué crees que esas etiquetas son las que tienen mejores y peores predicciones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "_Las etiquetas con mejores predicciones son 1,2,3,5 y 6 ya que no tienen ninguna incorrecta. Las peores son 4,7,8 y 9, donde 9 es la peor con 4 errores. Según como se tomaron los datos creo que las mejores son números que no son parecidos a ningún otro.  Este no es el caso de los peores, ya que por ej. el número 9 fácilmente se confunde con otros._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Ejercicio 9\n",
    "\n",
    "**_(10 puntos)_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "**Curva de aprendizaje:** Replica el ejemplo del siguiente [link](https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html#sphx-glr-auto-examples-model-selection-plot-learning-curve-py) pero solo utilizando un modelo de KNN con el hiperparámetro _k_ seleccionado anteriormente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate 3 plots: the test and training learning curve, the training\n",
    "    samples vs fit times curve, the fit times vs score curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    axes : array of 3 axes, optional (default=None)\n",
    "        Axes to use for plotting the curves.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 5-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - :term:`CV splitter`,\n",
    "          - An iterable yielding (train, test) splits as arrays of indices.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : int or None, optional (default=None)\n",
    "        Number of jobs to run in parallel.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "\n",
    "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
    "        Relative or absolute numbers of training examples that will be used to\n",
    "        generate the learning curve. If the dtype is float, it is regarded as a\n",
    "        fraction of the maximum size of the training set (that is determined\n",
    "        by the selected validation method), i.e. it has to be within (0, 1].\n",
    "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
    "        Note that for classification the number of samples usually have to\n",
    "        be big enough to contain at least one sample from each class.\n",
    "        (default: np.linspace(0.1, 1.0, 5))\n",
    "    \"\"\"\n",
    "    if axes is None:\n",
    "        _, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "    axes[0].set_title(title)\n",
    "    if ylim is not None:\n",
    "        axes[0].set_ylim(*ylim)\n",
    "    axes[0].set_xlabel(\"Training examples\")\n",
    "    axes[0].set_ylabel(\"Score\")\n",
    "\n",
    "    train_sizes, train_scores, test_scores, fit_times, _ = \\\n",
    "        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
    "                       train_sizes=train_sizes,\n",
    "                       return_times=True)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    fit_times_mean = np.mean(fit_times, axis=1)\n",
    "    fit_times_std = np.std(fit_times, axis=1)\n",
    "\n",
    "    # Plot learning curve\n",
    "    axes[0].grid()\n",
    "    axes[0].fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                         color=\"r\")\n",
    "    axes[0].fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                         color=\"g\")\n",
    "    axes[0].plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "                 label=\"Training score\")\n",
    "    axes[0].plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "                 label=\"Cross-validation score\")\n",
    "    axes[0].legend(loc=\"best\")\n",
    "\n",
    "    # Plot n_samples vs fit_times\n",
    "    axes[1].grid()\n",
    "    axes[1].plot(train_sizes, fit_times_mean, 'o-')\n",
    "    axes[1].fill_between(train_sizes, fit_times_mean - fit_times_std,\n",
    "                         fit_times_mean + fit_times_std, alpha=0.1)\n",
    "    axes[1].set_xlabel(\"Training examples\")\n",
    "    axes[1].set_ylabel(\"fit_times\")\n",
    "    axes[1].set_title(\"Scalability of the model\")\n",
    "\n",
    "    # Plot fit_time vs score\n",
    "    axes[2].grid()\n",
    "    axes[2].plot(fit_times_mean, test_scores_mean, 'o-')\n",
    "    axes[2].fill_between(fit_times_mean, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1)\n",
    "    axes[2].set_xlabel(\"fit_times\")\n",
    "    axes[2].set_ylabel(\"Score\")\n",
    "    axes[2].set_title(\"Performance of the model\")\n",
    "\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(10, 15))\n",
    "\n",
    "title = \"Learning Curves (KNeighborsClassifier)\"\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
    "estimator = best_knn\n",
    "plot_learning_curve(estimator, title, X, y, axes=axes, ylim=(0.7, 1.01),cv=cv, n_jobs=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "**Pregunta**\n",
    "\n",
    "* ¿Qué refleja este gráfico?\n",
    "* ¿Qué conclusiones puedes sacar a partir de él?\n",
    "* ¿En qué crees que hay que poner más atención a la hora de trabajar con un problema de clasificación?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "_El primer gráfico muestra los Training score y Cross-validation score para diferentes training examples. De él se puede apreciar que la curva de score para Training y Cross-validation tienen el mismo comportamiento (parten bajos y luego crecen hasta 'estabilizarce'), pero Training esta por sobre Cross-validation._\n",
    "\n",
    "_El segundo gráfico muestra el tiempo de ejecución para distintos training examples. Se puede concluir que el tiempo de ejecución aumente de manera considerable (quizás exponencial) en relación con el tamaño de la muestra._\n",
    "\n",
    "_El tercer gráfico muestra la relación de los tiempos del segundo gráfico con los scores del primero. Nos dice que a partir del tiempo 0.04, el score no cambia considerablemente, por lo que uniendo esta información con la del gráfico anterior no serían necesarios más de 800 training examples._\n",
    "\n",
    "_A mi parecer hay que poner más atención con el score en relación a los training examples ya que es algo fácil de manejar._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
